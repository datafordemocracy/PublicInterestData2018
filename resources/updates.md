## 2018-04-13
* MC: finished updating postreferral models (analysis_postreferral.R), added to document; generated initial figure summarizing model results for race (figure_predictions.R) and added to document.

## 2018-04-06
* MC: finished/updated disproportionality section; made Cville tract maps or child pop, referral rates, poverty rates and added to report. merged group 1 scripts into prep_postreferral.R, figures_postreferral.R, analysis_postreferral.R; added comments; made figures consistent throughout; added logit models for accept, tweaked logit models for investigate, substantiate, severity. Worked on matching referral and active for additional analysis (contact count and duration of services).

## 2018-03-30
* MC: explored data linking -- details at linkingdata.md; examined implications of coding of race -- details at racevar.md; generated example of clustered standard errors in R, and example of extracting initial foster care placement; updated baseline disproportionality. Adding to report.

### Group 1

* MW: I met with my group to discuss how we wanted to finalize our findings. I consolidated Hannah's and my graphs into one R file, where I added the specific coloring to the graphs. I uploaded this to the box and updated the progress report. I also added images and information to the latex document. I will continue to do this during the rest of the week.
* HS: This week I finished my logit models for race on investigation, finding, and finding level. I uploaded the code to the box, though did not add it to Sharelatex. I think there still needs to be some work done on refining the models, I am not sure that using "white" as the omitted category works super well? Or maybe I need to add more definitions of race outside of "children of color". I was also unsure about the effects of adding type of abuse versus priority level. Anyway, that was what I worked on this week. 
* JM: This week I looked at all of the code I have written for the class and put into words what I did. In addition, I am also in charge of LaTeX formatting for the group and taught my group how to use stargazer. As a group, we met on 3/28 to create a few best practices for how our graphs should look like and what information they should convey. This included specifying which race variable to look at. Personally, I also edited a lot of my previously written code and cleaned up the visualization. For the following weeks I will try to allocate time to continue working on this project because it has definitely been a blast!
* MW: This week, I worked on writing up the analysis of the two graphs I was responsible for in my group and organized a final report summary that has all of our group's information synthesized on it (which I will upload to the box after some more edits). Thank you again for helping me with my graphs on Sharelatex!
* NP: I reviewed my progress in this project and have concluded all my analysis below: I did analysis about the substantiation of abuse in different races; Clean data: (1) delete all DRS cases and remove all NAs, (2) Build “race_class” variable according to type, (3) Build “founded” variable which includes founded level 1,2,3. We have a question leaves here: in which cases, the government will choose to appealed? Founded or not founded?

### Group 2

* AW: I read through and edited the report on LaTex. I also added information for our Group's section and started brainstorming for the discussion & implication section. I played around with the html file that Charlotte made for our group last time.
* BA: Worked with Charlotte to understand the limitations of the data and discussed the potential solutions to merging the foster care data with referral data. Discusssed about selection of visualizations that needs to go into the report based on what is it that gets stakeholders would like to see. Finally, learnt the updates from the last weeks class. 
* CM: All scripts and the progress report have been updated to reflect the decision to limit the data to three years. I also added graphs and language to the LaTeX document, tried different visualizations for the data, and updated our group progress report. I have some questions about which models to include, and what language is relevant and or appropriate. 

## 2018-03-23
* MC: emailed lab with my updates, plans for Friday, and race coding review; wrote/added progress doc to box; work on report document.

### Group 1

* NP: I reviewed order logit regression and logit regression. And I use it to fit the disposition level. I separate founded levels from the other conditions and then train the data to see the relationship between race and disposition level.
I also use order logit regression to see the relationship between gender and disposition level, gender+race and disposition level.  Based on the model I built, white male tend to have a higher disposition level while multiracial male tend to have a lower disposition level. Besides, male tend to have a higher disposition level than female.
* MW: This week my group continued to create more models for the disposition variables. I went through past emails and documents, and added a progress document to the Box. While our group meeting time was hindered by the snow, we are continuing to progress with the analysis, and are starting to add the results to the final report.
* HS: This week I improved upon my regression analysis of Investigation status for the DSS data. I conducted regressions controlling for race, tract, gender, abuse type and priority. I am still working out how to visually show the probability of an investigation by tract, so that will be something to work on. I am also interested in doing another set of regressions for finding levels. 
* JM: I've looked more in depth at the referral_clients data. I'm also looking into creating more logit regressions for different race factors. In addition, I'm familiarizing myself with what a regression actually produces and to try to find a way to visualize my findings. Currently they are available as snippets of code. For next week I will try to add some information to the LaTeX file and reorganize things in Box.
* MW: As our group ran regressions on the Investigation on race, track, and abuse type, I began compiling our graphs and takeaways onto a final report document that we will edit and eventually link to the class's final report.

### Group 2

* CM: This week, I consolidated my group’s progress into an R markdown document with an HTML output (both on Box) so we can organize our thoughts and communicate with the rest of the class. I also added some new and different visualizations. Next week, I want to learn more about logit models and the Cox proportional hazard model.
* AW: 1. This week I learned from Charlotte's code and did some exploration and tried to use ggplot to make charts that I thought was useful from my reading last week. I also read some more articles on how to analyze since I think this would be the best way I could contribute.

## 2018-03-16
* MC: emailed groups my understanding of an outline of their work; annotated research chapter; updated `prep_basedisp.R` to add proportions by race in DSS referral data, updated `analysis_basedisp.R` to improve figures, generate disproportionality in referral point estimates and intervals by year; added more structure to report document, and started adding a little bit of content.

### Group 1

* HS: This week I read and summarized my assigned article. I also did initial logit regressions comparing the chances of an investigation for white and non-white children. I ran into some issues making combined dummy variables, that will hopefully be worked out in class. My main issue is that multiracial children are classified often as black and white, so they could be counted twice. I need to figure out a way to address this. I also pulled poverty statistics by census tract for some initial judgements on poverty and investigation. 
* NP: I read the assigned four articles carefully and made annotation that I thought could be useful to the project. I also tried to build models based on our discussion last class. Besides, through my readings, it seems considering changes in policies would make our analysis become too complex, since the changes could have different influence on different races.
* MW: I read the required articles and am just about to read the additional one! Our group is working to split the tasks you suggested for us in the previous email. I am particularly going to start looking at the following this weekend: time to first contact.
* MW: This week I summarized the krase 2015 article. I also worked on the referral dataset from last week, making the reporter relation variable into more general categories.
* JM: I familiarized myself with research done on disproportionality and disparity in child welfare from children in NYC.  It was pretty eye opening since it allowed me to see the raw statistics of children in another state. Something to keep in mind from reading this was that no matter what policy changes are implemented, we must maintain a wary mind on the effectiveness of the policy. This can be done by doing different analysis on state and county levels to see where the problem lies.

### Group 2

* BA: 1. Read two articles alloted to me and wrote a brief summary and how that fits into our analysis. A few questions popped up while doing so which migh be helpful in our analysis. 2. Cleaned the redundant code in the R file and upated it on github. Created a pull request to include the changes in the original file. 3. Created 3 types of race variables and created vizualizations for almost all the decison points. Have few questions on how to formulate the problem for few decision points.
* AW: Read through the assigned articles and gained a better understanding of the different ways that researchers can measure disproportionality. I enjoyed reading the two reports from University of Illinois and Child Welfare of Minnesota. The methods used in UofI-Urbana Champaign was more applicable to our data set and more likely for us to implement, while the ones from the Minnesota report heavily relied on data that we do not have. For example, it needed family conditions and reporter type, and these are data that CVille's CPS do not have.
* CM: This week I split my script into three parts (cleaning, analysis, and visualization) and got the data better organized and ready for analysis. Next week I want to dig more into the statistical models and make sure I really understand them. 
* NP: This week I worked on the Hornstein article and summary, read the childmaltreatment article, and looked at the prep_basedisp code.
* BE: I read and summarized the report, "Racial Disproportionality in Wisconsin's Child Welfare System" and posted my summary on Box ("bowman_etal_2009_summary_RGE."). I also updated my group's google doc page, just with our current charge and where we are, conglomerating messages between us, the lab's online pages, and the email from you last week. I peered into codes/scripts posted on Box, still trying to gain an understanding of R commands and keeping my own giant script updated with my notes. I am currently trying to *fully* understand piping. 

## 2018-03-02
* MC: pulled together some articles -- from the research synthesis and a search in web of science of work since 2011 -- read abstracts, downloaded ones that seemed most relevant, skimmed to situate it within our work, and sent out summary info to lab; sent race coding instructions. Downoaded and wrangled ACS 5-year estimates to generate estimates of children by race in Cville, merged with summary data on referrals by race (see `prep_basedisp.R`) and started lookiing at data (see `analysis_basedisp.R`). Updated GitHub and webpages with agenda.

### Group 1

* NP: This week my group met and revised our work plan to include only questions relating to the referral and the on going data. We discussed some initial thoughts about exploring this data and how to code the new race variables. In the end, we split up different outcomes to graph visually with race to get a feel for the distribution of our data. We will present these in class. 
* HS: This week my group met and revised our work plan to include only questions relating to the referral and the on going data. We discussed some initial thoughts about exploring this data and how to code the new race variables. In the end, we split up different outcomes to graph visually with race to get a feel for the distribution of our data. We will present these in class. 
* MW: I met with my team members to discuss how we should reframe our proposal to focus on the referral data. We came up with a few new variables, and decided which ones to do exploratory analysis on. I was assigned to graph the differences between first reporter relation for each race, which I uploaded to our team google drive.
* MW: My group and I (Group 1) met and determined our new questions using only the Referral and Ongoing Clients data. We organized what charts we wanted to use to determine the relationship between race and the data points (we choose mostly bar charts for now) and split them up accordingly. I made the bar charts for (Acceptance Frequency vs. Race) and (Screened Out vs. Race) for each of the 3 definitions of race we defined last class to see any differences between the results. I also made a google powerpoint to help the group show their results while I am not there in person. 
* JM: This week our group met to discuss which variables to look at specifically to perform our first analysis. I am in charge of Initial contact time. It was tough since I had to figure out to find a numeric in which the time in and time out could be represented. Through this, I made a visualization of frequency of children vs time spent.

### Group 2

* BA: Created three new variables for race based on the your email last week. Re-organizing the data since there are many dataframes in our R code last week. Tried to create more conscise and clear datasets. Explored the variables that can go into the models at decisions points discussed for the foster care data which has unique client ids. Copied the variables from the placement data to foster care dataframe,  the variables which were unique for clients such as number of placements and time in placements etc.
* AW:  I played around with the data sets to do preliminary analysis, I had a hard time manipulating the data into the difference codings of race. I watched a couple videos on lynda.com but still had a little trouble applying it to our data. I look forward to learning what other people has done with the preliminary analysis in class, I think I'll learn a lot by seeing the different ways to do it. I have also read a couple chapters of the Child Maltreatment 2016 report.
* CM: This week, I did some baseline exploratory data analysis. It looks like placement category seems evenly broken up by race, where discharge from the system does seem to have some variation by race. I wondered whether face to face count was different for children of different racial categories, but after controlling for number of placements, there don’t seem to be significant differences. 

## 2018-02-23
* MC: added each group's code to read in, check, format data to GitHub (added a few comments or headers here and there); started a document on ShareLaTeX for collaborative report; started analysis plan for problem statement q1 (see `Q1update_feb22_mpc.doc,` `get_acs.R`); planned Friday's agenda and prepped short regression review; also added `git_steps.md` from publicpresidency repo as guidance to lab members who want to fork the repo and contribute directly via pull requests (if this describes you and you want to walk through things, let me know).

### Group 1

* NP: I caught up with last week's class material and read the resource carefully. I also reviewed the dataset again and found several interesting features I had not thought about. For instance,  the "face to face count” and “face to face home count” seems valuable for our research of racial disparity. Also, in the group discussion, I found that this dataset actually consists of information for nearly 20 years, and this finding makes me question whether the policies changes heavily influence the foster care system. Also, the demographic features may change a lot, and there may be more minorities in Charlottesville than before. Thus, I am wondering whether we should focus on count or percentage. 
* MW: This week I met with my group, where we discussed the variables and outcomes we wanted to use in tackling the problem. We made our discussion into a written report, which was then submitted. One thing we had trouble with was figuring out how to visualize any models we made, since the default decision tree output is not easily readable to an outsider.
* HS: This week I met up with my group and we talked through and created research plan based on the question we were given. This was mostly successful, though we do have some questions about our ability to pull neighborhood income from census tract and probably need more information about welfare policies that have changed over time that might affect our results. 
* MW: This week, our group developed our outline for research question #2: Racial disparity in post-referral decision points. Individually, I learned how to run the Monte Carlo analysis for the sensitivity of independent variables on dependent variables on excel. The result will be in the form of a distribution with confidence intervals, as well as an indication of the topmost "sensitive" variables in terms of influencing the dependent variable. Once our group runs the regression on our post-referral decision points, I hope to see if this analysis will add value and increased specificity to our analysis on R. 
* JM: This week we breaking up into groups to tackle different parts of the problem statement. We met up as a group to discuss the research plan and were able to create a written report. We also talked about our role as researchers in this project. Personally, I will go through Hadley's chapter 23-25.

### Group 2

* AW:  I worked with my team to go through the foster care data and explored ideas on how to identify disproportionality. It was also interesting to think about what factors should be included in our model, and learn about different ways to explore the dataset. Furthermore, on Wednesday, I  attended the "Data Manipulation with dplyr" workshop by the Health Sciences Library. I learned about the different verbs in the package, and now I feel more comfortable doing initial exploration. 
* CM: I met with my group, went over and explained our script to our new group members, and played around a little bit more with visualizations. I also made a GitHub, forked the project, and uploaded my script! I learned about survival models, and I think they could be useful in modeling time spent in the system.
* BA: We thought about what decision points might be critical in showing disparity. We have few points written down. But, we would have to build models to see which ones stand out. The details are included in the report. Other than that I was working on including some random forest models. But, will have to see if they work well comparatively.
* BE: First, I moved the data back into an encrypted folder on my desktop, deleted VeraCrypt and all that more complicated stuff, and fixed R and my working directory so that I could run mine and other peoples' scripts... Second, I communicated with my previous group about the foster care data code... read (new code) and compared it to old code that we had looked over in class and that you had made comments on. I made sure the new code addressed all these comments and we agreed that it did... Third, I met with my new group. We walked through (the) code step by step and talked through it, to make sure each of us understood what was happening. We had done some of this in class, but it was great to do it in a small group because things were explained at a different speed and using different language. Before our meeting, I had set up a google doc for our group with some basic info like the problem statement and our charge for the week and everyone's contact info. Everyone seemed to like it and agreed that they would like the doc to be updated with next week's assignment as well. We went onto this document as we discussed the question we are charged with and our role in addressing it.

## 2018-02-16
* MC: quick review of each group's code, more exploration of data, combine/revise problem statement for discussion and further revision, set Friday's agenda, read some literature on geographic context cited in the research synthesis.
* MW: This week I edited my R script and responded to the comments. I'm not sure whether the comments were made by you or by other students, but they were very helpful for clarifying and potential errors I made. Things that I might have found clear after looking extensively at the data might not be obvious to an outsider, so in the future I need to provide answers to these questions in my analysis. I also looked at the referral data and did the code review/added comments.
* HS: This week my group updated the code book with the additional information from Jenny. We also reviewed our code and incorporated the comments we received. This included adding more comments, grouping by case id and checking for outliers. One difficult part of the week was figuring out how to look for outliers in the data. We did a couple of things, but aren't sure if that is what to look for. I also created a version of the referral code with comments. 
* CM: This week I got some more census and ACS data by block group, updated my script with a binary indicator of ongoing cases, a duration variable with a dummy data retrieval date (not sure when that was), and explored some new visualization! N
* NP: Since last week in class our group realized that data visualization will be very important,  I am exploring new ways right now. Also, I am doing research about children’s psychology. I want to know whether we should keep exploring the age and gender effects. 
* AW: I was able to go through the explore_referraldata and my group's ongoing_clients data searched up functions that I didn't understand and didn't have a full grasp of. I now have more background on how the data is structured and better understand what should be done.
* MW: This week I looked more into potential tests we can do to analyze the data. There is this spreadsheet-based application called Oracle Crystal Ball that can be used to find the "sensitivity" of various variables and the impact of their potential values on the ultimate output variable. This could be used if later one we want to run a regression analysis on how various factors impact the likelihood of a child with being screened in. There are also other analyses on the probability and sensitivity of various variables on an outcome, called the Monte Carlo and Tornado Analysis. I will be attending a session on using Crystal Ball this afternoon so I will have a better idea of how to use it afterward. 
* JM: This week I created a personal R script of initial analysis based on a cleaning of CPS_Ongoing which was submitted to the box. I also commented on the code of others. Finally, I made sure that my code was compatible with VeraCrypt, which for some reason works differently between windows and mac which might serve as a point of error in terms of open source data. I also added to the data dictionary after our meeting with Jenny last week.

## 2018-02-09
* MC: updated explore_referraldata.R -- added comments, more cleaning, more exploration; set Friday's agenda, added code review questions


### Group 1 

* AW: My group and I explored the data for the Ongoing Clients, we were able to clean the data for it to be in a clearer format. I was also able to walk through our exploration R file from class and try to understand the steps. 
* HS: We explored the data set On_Going reports and renamed variables to make them clearer. We also factored categorical data points. We set up a meeting with Jenny Jones at DSS to explore our questions further.
* JM: This week my team and I met with Jenny from the Department of Social Services. We were able to parse further information from the Data Dictionary which will influence our analysis. I personally cleaned CPS_Ongoing but had questions about what items should be factors.

### Group 2

* MW: I worked on the R Script for the Foster Care dataset. Since we don't have any questions to investigate yet, I just looked for differences between white and non-white kids in the system.
* NP: I used R to analyze the foster care dataset. I focused on the age variable. Here are some interesting findings:
  * First, generally, children whose age is around five have the highest chance to be put in the Legal Custody.
  * Second, girls and boys who are in the Legal Custody have different age distributions. For children whose age is below 8, boys are more likely to get into the Legal Custody. However, after 8, there are more girls getting into the Legal Custody.
  * Third, children from different races have different age distribution. For instance, African American children are more likely getting into the Legal Custody around age 1,5 and 15. However, white children are more likely to get into the Legal Custody at 16 and 17 years old.
* NP: This week I worked on looking through the Charlottesville open data. I identified 4 data sets that may be useful to us. The census tracts have geographical and demographic information that is relevant to our project. The crime data may be used to assess the risk that a child may face in a geographical area. Finally, the real estate assessment may give us some indication of income. 
* BE: NP uploaded the local, geographical data we thought would be useful from the Charlottesville Open Data Portal. The sets might relate to some of our lab's questions, to the census, or to foster children's exposure to social services or probability of harm. The open data chosen includes US Census Block Group Data, US Census Block Area, Crime Data, and Real Estate Current Assessments. Additionally, I had signed up for the "Help! I need to use the Census" workshop this week but had to miss that. 

### Group 3

* MW: I met with my group and we looked through the initial Social Explorer Tract Level ACS Census data. Specifically, I pulled out data on Charlottesville's 2016 Total Population, Sex, Sex by Age, Race, Poverty Status in for Children
 Under 18, Poverty Status based on Race, Means of Transportation to Work for Workers 16 Years and Over, and Travel Time to Work for Workers 16 years and Over.
* CM: I really enjoyed learning R and exploring the data this week. I’m new to R but I was able to build out a cleaning script, and that was the one my group decided to use so I was proud of that! I hit a number of roadblocks in trying to figure out how to group the placement data in a way it could be merged with the other data because placements are listed separated, but with extensive Googling and reading, I figured it out. 
* BA: We've cleaned up the placements data and created some new variables that we thought might be helpful. But, there are few questions in the that we wanted to run by you in orded to make changes to the data set. Secondly, going to the census workshop was of great help. But, after listening to Jenn talk about how the data is collected, I wouldn't recommend we use ACS data afterall. We would have to look if the 95% confidence intervals of the data aren't overlapping for all the tracts if we want to use them. Or we can't just prove that the data for the tracts are accurate or if there is a significant difference in the the tract data.
